{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packagesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.4.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from azureml.core import Workspace, Dataset\n",
    "import azureml.core\n",
    "import os\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-environment\teastus\tAIMLDemo\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='ml-environment', subscription_id='483b73e5-b0bf-40ea-840d-cdb839f75a3b', resource_group='AIMLDemo')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'sklearn-storage-prediction'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create or Attach existing compute resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target: cpu-cluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print(\"found compute target: \" + compute_name)\n",
    "else:\n",
    "    print(\"creating new compute target...\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Year</th>\n",
       "      <th>Pie_id_1_stock</th>\n",
       "      <th>Pie_id_2_stock</th>\n",
       "      <th>Pie_id_3_stock</th>\n",
       "      <th>Pie_id_4_stock</th>\n",
       "      <th>Pie_id_5_stock</th>\n",
       "      <th>Pie_id_6_stock</th>\n",
       "      <th>Pie_id_7_stock</th>\n",
       "      <th>Pie_id_8_stock</th>\n",
       "      <th>Pie_id_9_stock</th>\n",
       "      <th>Pie_id_10_stock</th>\n",
       "      <th>Pie_id_11_stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Week  Year  Pie_id_1_stock  Pie_id_2_stock  Pie_id_3_stock  Pie_id_4_stock  \\\n",
       "0     1  2020               5               9               9               4   \n",
       "1     2  2020               2               6               9               8   \n",
       "2     3  2020               9               7               9               5   \n",
       "3     4  2020               1               8               0               2   \n",
       "4     5  2020               6               4               8               4   \n",
       "\n",
       "   Pie_id_5_stock  Pie_id_6_stock  Pie_id_7_stock  Pie_id_8_stock  \\\n",
       "0               6               3               8               2   \n",
       "1               6               8               6               6   \n",
       "2               9               7               1               3   \n",
       "3               5               2               1               3   \n",
       "4               7               3               7               0   \n",
       "\n",
       "   Pie_id_9_stock  Pie_id_10_stock  Pie_id_11_stock  \n",
       "0               5                6                7  \n",
       "1               5                9                8  \n",
       "2               9                9                8  \n",
       "3               2                3                2  \n",
       "4               1                0                0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(ws, name='storage')\n",
    "storage = dataset.to_pandas_dataframe()\n",
    "storage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a directory\n",
    "\n",
    "Create a directory to deliver the necessary code from your computer to the remote resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = os.path.join(os.getcwd(), \"sklearn-storage-prediction\")\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the trainig code\n",
    "- Everything should be included in the script below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "from azureml.core import Run\n",
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "dataset = Dataset.get_by_name(ws, name='storage')\n",
    "storage = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "storage = storage.drop(['Month'], axis=1, errors='ignore')\n",
    "storage.insert(2, 'Month', [1,1,1,1,2,2,2,2,3,3,3,3,3,4,4,4,4,5,5,5,5,\n",
    "                            6,6,6,6,6,7,7,7,7,8,8,8,8,8,9,9,9,9,10,10,10,10,11,11,11,11,11,12,12,12,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columnName in storage.columns.drop(['Week','Year','Month']):\n",
    "    prior1 = columnName+\"_1_week_ago\"\n",
    "    prior2 = columnName+\"_2_week_ago\"\n",
    "    storage = storage.drop([prior1], axis=1, errors='ignore')\n",
    "    storage = storage.drop([prior2], axis=1, errors='ignore')\n",
    "    storage.insert(3, prior1, storage[columnName].shift(1))\n",
    "    storage.insert(3, prior2, storage[columnName].shift(2))\n",
    "    \n",
    "storage=storage.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentPie = 'Pie_id_1_stock'\n",
    "tempDf = storage.loc[:,['Week','Year','Month',(currentPie),(currentPie+'_1_week_ago'),(currentPie+'_2_week_ago')]]\n",
    "\n",
    "x_train = tempDf.loc[0:math.floor(tempDf.shape[0]/3)*2,tempDf.columns.drop(currentPie)]\n",
    "x_test = tempDf.loc[math.floor(tempDf.shape[0]/3)*2+1:,tempDf.columns.drop(currentPie)]\n",
    "y_train = tempDf[currentPie].loc[0:math.floor(tempDf.shape[0]/3)*2]\n",
    "y_test = tempDf[currentPie].loc[math.floor(tempDf.shape[0]/3)*2+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train);\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.0\n",
      "Attempted to log scalar metric accuracy:\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['outputs/sklearn-storage-prediction_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "# calculate accuracy on the prediction\n",
    "acc = np.average(predictions == y_test)\n",
    "print('Accuracy is', acc)\n",
    "\n",
    "\n",
    "run.log('accuracy', np.float(acc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=rf, filename='outputs/sklearn-storage-prediction_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a actual training script\n",
    "\n",
    "To submit the job to the cluster, first create a training script. Run the following code to create the training script called `train.py` in the directory you just created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/bethanys-ml-compute/code/users/apdarr/bethanys/sklearn-storage-prediction/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace,Dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "from azureml.core import Run\n",
    "from utils import load_data\n",
    "\n",
    "\n",
    "\n",
    "# let user feed in 2 parameters, the dataset to mount or download, and the regularization rate of the logistic regression model\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--week', type=int, dest='week', help='week of the wanted estimate')\n",
    "# parser.add_argument('--year', type=int, dest='year', help='year of the wanted estimate')\n",
    "# parser.add_argument('--month', type=int, dest='month', help='month of the wanted estimate')\n",
    "# parser.add_argument('--stock_1_week_ago', type=int, dest='stock_1_week_ago', help='stock the week before the wanted week')\n",
    "# parser.add_argument('--stock_2_week_ago', type=int, dest='stock_2_week_ago', help='stock the 2 weeks before the wanted week')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# data_folder = args.data_folder\n",
    "# print('Data folder:', data_folder)\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "workspace = run.experiment.workspace\n",
    "dataset_name = 'storage'\n",
    "# Get a dataset by name\n",
    "dataset = Dataset.get_by_name(workspace=workspace, name=dataset_name)\n",
    "storage = dataset.to_pandas_dataframe()\n",
    "\n",
    "storage = storage.drop(['Month'], axis=1, errors='ignore')\n",
    "storage.insert(2, 'Month', [1,1,1,1,2,2,2,2,3,3,3,3,3,4,4,4,4,5,5,5,5,\n",
    "                            6,6,6,6,6,7,7,7,7,8,8,8,8,8,9,9,9,9,10,10,10,10,11,11,11,11,11,12,12,12,12])\n",
    "\n",
    "for columnName in storage.columns.drop(['Week','Year','Month']):\n",
    "    prior1 = columnName+\"_1_week_ago\"\n",
    "    prior2 = columnName+\"_2_week_ago\"\n",
    "    storage = storage.drop([prior1], axis=1, errors='ignore')\n",
    "    storage = storage.drop([prior2], axis=1, errors='ignore')\n",
    "    storage.insert(3, prior1, storage[columnName].shift(1))\n",
    "    storage.insert(3, prior2, storage[columnName].shift(2))\n",
    "    \n",
    "storage=storage.fillna(0)\n",
    "    \n",
    "\n",
    "currentPie = 'Pie_id_1_stock'\n",
    "tempDf = storage.loc[:,['Week','Year','Month',(currentPie),(currentPie+'_1_week_ago'),(currentPie+'_2_week_ago')]]\n",
    "\n",
    "x_train = tempDf.loc[0:math.floor(tempDf.shape[0]/3)*2,tempDf.columns.drop(currentPie)]\n",
    "x_test = tempDf.loc[math.floor(tempDf.shape[0]/3)*2+1:,tempDf.columns.drop(currentPie)]\n",
    "# x_test = [args.week,args.year,args.month,args.stock_1_week_ago,args.stock_1_week_ago]\n",
    "y_train = tempDf[currentPie].loc[0:math.floor(tempDf.shape[0]/3)*2]\n",
    "y_test = tempDf[currentPie].loc[math.floor(tempDf.shape[0]/3)*2+1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train);\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "\n",
    "# calculate accuracy on the prediction\n",
    "acc = np.average(predictions == y_test)\n",
    "print('Accuracy is', acc)\n",
    "\n",
    "\n",
    "run.log('accuracy', np.float(acc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=rf, filename='outputs/sklearn-storage-prediction_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `utils.py` is referenced from the training script to load the dataset correctly.  Copy this script into the script folder so that it can be accessed along with the training script on the remote resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/bethanys-ml-compute/code/users/apdarr/bethanys/sklearn-storage-prediction/utils.py'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.copy('utils.py', script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an estimator\n",
    "\n",
    "An estimator object is used to submit the run. Azure Machine Learning has pre-configured estimators for common machine learning frameworks, as well as generic Estimator. Create an estimator by specifying\n",
    "\n",
    "* The name of the estimator object, `est`\n",
    "* The directory that contains your scripts. All the files in this directory are uploaded into the cluster nodes for execution. \n",
    "* The compute target.  In this case you will use the AmlCompute you created\n",
    "* The training script name, train.py\n",
    "* An environment that contains the libraries needed to run the script\n",
    "* Parameters required from the training script. \n",
    "\n",
    "In this tutorial, the target is AmlCompute. All files in the script folder are uploaded into the cluster nodes for execution. The data_folder is set to use the dataset.\n",
    "\n",
    "First, create the environment that contains: the scikit-learn library, azureml-dataprep required for accessing the dataset, and azureml-defaults which contains the dependencies for logging metrics. The azureml-defaults also contains the dependencies required for deploying the model as a web service later in the part 2 of the tutorial.\n",
    "\n",
    "Once the environment is defined, register it with the Workspace to re-use it in part 2 of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"bethanys-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-dataprep[pandas,fuse]>=1.1.14\",\n",
       "                        \"azureml-defaults\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn==0.22.1\"\n",
       "            ],\n",
       "            \"name\": \"azureml_1da05dd5d5e4887f2cd965a6ef22023b\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# to install required packages\n",
    "env = Environment('bethanys-env')\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-dataprep[pandas,fuse]>=1.1.14', 'azureml-defaults'], conda_packages = ['scikit-learn==0.22.1'])\n",
    "\n",
    "env.python.conda_dependencies = cd\n",
    "\n",
    "# Register environment to re-use later\n",
    "env.register(workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the job to the cluster\n",
    "\n",
    "Run the experiment by submitting the estimator object. And you can navigate to Azure portal to monitor the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "   }\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target,\n",
    "              environment_definition=env,\n",
    "              entry_script='train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>sklearn-storage-prediction</td><td>sklearn-storage-prediction_1589439291_9c3f6b4f</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/experiments/sklearn-storage-prediction/runs/sklearn-storage-prediction_1589439291_9c3f6b4f?wsid=/subscriptions/483b73e5-b0bf-40ea-840d-cdb839f75a3b/resourcegroups/AIMLDemo/workspaces/ml-environment\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: sklearn-storage-prediction,\n",
       "Id: sklearn-storage-prediction_1589439291_9c3f6b4f,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2b5ad3dfb24d59b0da97c94bd6520e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Queued\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/sklearn-storage-prediction/runs/sklearn-storage-prediction_1589439291_9c3f6b4f?wsid=/subscriptions/483b73e5-b0bf-40ea-840d-cdb839f75a3b/resourcegroups/AIMLDemo/workspaces/ml-environment\", \"run_id\": \"sklearn-storage-prediction_1589439291_9c3f6b4f\", \"run_properties\": {\"run_id\": \"sklearn-storage-prediction_1589439291_9c3f6b4f\", \"created_utc\": \"2020-05-14T06:54:54.383964Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"ede1e08c-5b04-460d-bfe0-ce08b6e923d6\", \"AzureML.DerivedImageName\": \"azureml/azureml_7b48670a0423858f69b60b23972c8e06\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"resizing\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Queued\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:05:14\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"Your job is submitted in Azure cloud and we are monitoring to get logs...\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.4.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: sklearn-storage-prediction_1589439291_9c3f6b4f\n",
      "Web View: https://ml.azure.com/experiments/sklearn-storage-prediction/runs/sklearn-storage-prediction_1589439291_9c3f6b4f?wsid=/subscriptions/483b73e5-b0bf-40ea-840d-cdb839f75a3b/resourcegroups/AIMLDemo/workspaces/ml-environment\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-05-14T07:01:06Z Starting output-watcher...\n",
      "2020-05-14T07:01:06Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "9125e2303251fcff723c8bcdfce6a8d647f25e3fe8d9d6b2dcd6456722e1b70a\n",
      "2020/05/14 07:02:47 Instrumentation Key Is Empty Skipping App Insight Logger\n",
      "2020/05/14 07:02:47 Version: 3.0.01220.0001 Branch: master Commit: 1565d0f6\n",
      "2020/05/14 07:02:47 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/05/14 07:02:47 sshd inside container not required for job, skipping setup.\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job preparation. Current time:2020-05-14T07:02:48.080577\n",
      "Starting job preparation. Current time:2020-05-14T07:02:48.787684\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "2020/05/14 07:02:51 Instrumentation Key Is Empty Skipping App Insight Logger\n",
      "Entering context manager injector. Current time:2020-05-14T07:02:52.970960\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 100\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ train.py ] with arguments: []\n",
      "After variable expansion, calling script [ train.py ] with arguments: []\n",
      "\n",
      "Accuracy is 0.0\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 100\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 1.8836743831634521 seconds\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job release. Current time:2020-05-14T07:03:17.963095\n",
      "Starting job release. Current time:2020-05-14T07:03:18.959406\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 295\n",
      "Entering context manager injector. Current time:2020-05-14T07:03:18.979051\n",
      "Job release is complete. Current time:2020-05-14T07:03:23.058083\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: sklearn-storage-prediction_1589439291_9c3f6b4f\n",
      "Web View: https://ml.azure.com/experiments/sklearn-storage-prediction/runs/sklearn-storage-prediction_1589439291_9c3f6b4f?wsid=/subscriptions/483b73e5-b0bf-40ea-840d-cdb839f75a3b/resourcegroups/AIMLDemo/workspaces/ml-environment\n",
      "\n",
      "Warnings:\n",
      "This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\n",
      "Please enable Docker in the environment section of your run configuration to stop seeing this warning message.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'sklearn-storage-prediction_1589439291_9c3f6b4f',\n",
       " 'target': 'cpu-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-05-14T07:01:00.126024Z',\n",
       " 'endTimeUtc': '2020-05-14T07:03:26.711567Z',\n",
       " 'warnings': [{'message': \"This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\"}],\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'ede1e08c-5b04-460d-bfe0-ce08b6e923d6',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_7b48670a0423858f69b60b23972c8e06',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'eb6fb24f-0ee3-4051-8a1f-9281d0e4f376'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cpu-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'bethanys-env',\n",
       "   'version': '1',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-dataprep[pandas,fuse]>=1.1.14', 'azureml-defaults']},\n",
       "      'scikit-learn==0.22.1'],\n",
       "     'name': 'azureml_1da05dd5d5e4887f2cd965a6ef22023b'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'itpCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt': 'https://mlenvirostorage8888719c4.blob.core.windows.net/azureml/ExperimentRun/dcid.sklearn-storage-prediction_1589439291_9c3f6b4f/azureml-logs/55_azureml-execution-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt?sv=2019-02-02&sr=b&sig=vgVxLzGrI%2Fuuzok%2FD35BOOiaF7g1XSo%2BS9o5U3re7Yc%3D&st=2020-05-14T06%3A53%3A29Z&se=2020-05-14T15%3A03%3A29Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt': 'https://mlenvirostorage8888719c4.blob.core.windows.net/azureml/ExperimentRun/dcid.sklearn-storage-prediction_1589439291_9c3f6b4f/azureml-logs/65_job_prep-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt?sv=2019-02-02&sr=b&sig=7RL%2FxS%2F2rPCdw17cXb20zK1D7QHAN2fGF9GVo4QVB7w%3D&st=2020-05-14T06%3A53%3A29Z&se=2020-05-14T15%3A03%3A29Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mlenvirostorage8888719c4.blob.core.windows.net/azureml/ExperimentRun/dcid.sklearn-storage-prediction_1589439291_9c3f6b4f/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=RPo%2F8raTYJIaOTLfwef4aWBR2U2A3Ikm5lCkypYL%2BUY%3D&st=2020-05-14T06%3A53%3A29Z&se=2020-05-14T15%3A03%3A29Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt': 'https://mlenvirostorage8888719c4.blob.core.windows.net/azureml/ExperimentRun/dcid.sklearn-storage-prediction_1589439291_9c3f6b4f/azureml-logs/75_job_post-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt?sv=2019-02-02&sr=b&sig=LN5Ddq8krqB9Rp36lpAG%2BlSzOsYBku%2BNXcKKl6E56fo%3D&st=2020-05-14T06%3A53%3A29Z&se=2020-05-14T15%3A03%3A29Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://mlenvirostorage8888719c4.blob.core.windows.net/azureml/ExperimentRun/dcid.sklearn-storage-prediction_1589439291_9c3f6b4f/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=26f3RRn8N3JhhVi2EhQQWSBgWJeXmkV8jf9B0Vb%2B528%3D&st=2020-05-14T06%3A53%3A29Z&se=2020-05-14T15%3A03%3A29Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://mlenvirostorage8888719c4.blob.core.windows.net/azureml/ExperimentRun/dcid.sklearn-storage-prediction_1589439291_9c3f6b4f/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=lkqejw7p3eI%2B4YH1%2Fg0ASjagUx2XXfvLUbDYx33tXr0%3D&st=2020-05-14T06%3A53%3A30Z&se=2020-05-14T15%3A03%3A30Z&sp=r',\n",
       "  'logs/azureml/100_azureml.log': 'https://mlenvirostorage8888719c4.blob.core.windows.net/azureml/ExperimentRun/dcid.sklearn-storage-prediction_1589439291_9c3f6b4f/logs/azureml/100_azureml.log?sv=2019-02-02&sr=b&sig=P%2BBPtXTatgURINdSIIPIZ6OG6Qn8jcp4jpHFGRJVnGg%3D&st=2020-05-14T06%3A53%3A29Z&se=2020-05-14T15%3A03%3A29Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://mlenvirostorage8888719c4.blob.core.windows.net/azureml/ExperimentRun/dcid.sklearn-storage-prediction_1589439291_9c3f6b4f/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=hTnsbCpe6DjhR8UVmOfSKYpvDq79mPVcAzXIlPWHpi4%3D&st=2020-05-14T06%3A53%3A29Z&se=2020-05-14T15%3A03%3A29Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://mlenvirostorage8888719c4.blob.core.windows.net/azureml/ExperimentRun/dcid.sklearn-storage-prediction_1589439291_9c3f6b4f/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=5Jr2P1k48PzHstsmnwCmdRQBMOK1US5ssNxX0PLY1J4%3D&st=2020-05-14T06%3A53%3A29Z&se=2020-05-14T15%3A03%3A29Z&sp=r'}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify show_output to True for a verbose log\n",
    "run.wait_for_completion(show_output=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azureml-logs/55_azureml-execution-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt', 'azureml-logs/65_job_prep-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_8103651318e5fdfb0a8c3de7ea4353c929ffb52f72ca2ca9bacc9d0d161f1707_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/100_azureml.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/sklearn-storage-prediction_model.pkl']\n"
     ]
    }
   ],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn-storage-prediction\tsklearn-storage-prediction:1\t1\n"
     ]
    }
   ],
   "source": [
    "# register model \n",
    "model = run.register_model(model_name='sklearn-storage-prediction', model_path='outputs/sklearn-storage-prediction_model.pkl')\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
